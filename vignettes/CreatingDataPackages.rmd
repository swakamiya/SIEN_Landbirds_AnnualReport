---
title: "Creating Data Packages"
date: "4/23/2020"
output:
  html_document:
    df_print: kable
    fig_caption: true
    dev: svg
    highlight: haddock
    keep_md: no
    smart: no
    theme: journal
    css: "../common/journalnps.min.css"
    toc: yes
    toc_float: true
    number_sections: false

---

```{r setup, include=FALSE}
RRpackages <- c('markdown',     # links to Sundown rendering library
                'rmarkdown',    # newer rendering via pandoc
                'pander',       # alternative renderer for markdown,
                                # plus better tables than just knitr
                'knitr',
                "devtools",
                "R.rsp",        # dynamic generation of scientific reports
                "rmdHelpers",   # misc from Mark Peterson
                                #  thisFileName() thisFile_knit()
                'yaml',         # format data into markdown
                'kableExtra',
                'rmdformats',   # templates including automatic ToC,
                                # also use_bookdown()
                "remotes",      # for install_github()
                'htmltools'     #
                )

inst <- RRpackages %in% installed.packages()
if (length(RRpackages[!inst]) > 0) {
   install.packages(RRpackages[!inst], dep = TRUE)
}

lapply(RRpackages, library, character.only = TRUE)

if (! "EMLassemblyline" %in% installed.packages()) remotes::install_github("EDIorg/EMLassemblyline")
require("EMLassemblyline")  

knitr::opts_chunk$set(
   echo = TRUE,
   comment = " ",
   dev = "svg",
   tidy.opts = list(width.cutoff = 60),
   tidy = TRUE
   )

```

# Step 1. Getting Started
The template package contains a folder with all of the files needed to (fairly) quickly create a data packge. Most of the information will come from the parameters associated with the data release report (this helps ensure consistency across files), but there are a few things that will need to be manually edited and checked before a data package can be finalized. 

The script provided with the template *only* works with tabular datasets created using the the data release report template, and produces EML-compliant metadata.

Once the script is finalized for a dataset, it can be re-run in its entirety to recreate the data package and component parts.

## Make sure you have the metadata-creation packages.
1. **EMLassemblyline.** Package developed by EDI.org. As per their github repository, it's designed "for scientists and data managers who need to easily create high quality EML metadata for data publication. EMLassemblyline is a metadata builder that emphasizes auto-extraction of metadata, appends value added content, and inputs user supplied information through common interfaces thereby minimizing user effort while maximizing metadata features for data discovery and reuse." Note that this package is not available on CRAN and must be manually installed.

  ` remotes::install_github("EDIorg/EMLassemblyline")` 


## Copy Template folder to a new directory.
1. Locate the `/dataPackages/DataPackageTemplate` folder and copy it to a new folder with a name of your choice in the same directory.
2. Within the newly-copied folder rename the `run_EMLassemblyline_for_XX.R` script as appropriate. 

# Step 2. Set Data Package Script Parameters

1. `dirName1`. Name of the directory where the data packaging scripts are stored. This should just be the directory name (such as "2018_Analysis_PORs"); not the whole path.
2. `dataset2Package`. The path to the saved data file you want to packge up (such as "data/final/FedTandEclean.RData").
3. `packageRefID1`.  Parameter containing the Data Store Reference ID for the data package (params$dataPackage1RefID).
4. `datapackageTitle`. Parameter containing the official title of the data package (params$dataPackage1Title).
5. `datapackageDescription`. parameter containing the data package description (params$dataPackage1Description).

# Step 3. Create the Delimited File.
1. Run all the lines in Step 3. This will take the data frame and write it to the `data_objects` directory as a csv file with the appropriate name.

# Step 4. Review or Edit the "Easy" Template Files

## keywords.txt
Keywords facilitate search and discovery on scientific terms, as well as names of research groups, field stations, and other organizations. Using a controlled vocabulary or thesaurus vastly improves discovery (e.g. LTER.

**keywords.txt** is a tab delimited table with columns:

-  **keyword** One keyword per row.
-  **keywordThesaurus** (optional) URI of controlled vocabulary from which the keyword was found.

```{r keywordsExample, echo=FALSE}

Table1<-read.delim(file="../dataPackages/dataPackageTemplate/metadata_templates/keywords.txt")

kable(Table1, 
      col.names=c("keyword","keywordThesaurus"),
      caption="**Table 1.** Example Keywords Table.") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),full_width=F)

```
## personnel.txt
Personnel and funding information facilitates attribution and credit for the data package.

**personnel.txt** is a tab delimited table with columns:

- **givenName** First name
- **middleInitial** (optional) Middle initial
- **surName** Last name
- **organizationName** Organization the person is associated with
- **electronicMailAddress** Email address
- **userId** (optional) Person’s unique identifier (e.g. ORCID).
- **role** Person’s role with respect to the data package. Persons serving more than one role, or roles shared among more than one person, should be added as separate lines. Valid roles are:
  -  **creator** Data package author
  -  **PI** (optional) Principal investigator associated with the data package.
  -  **contact** Data package contact. Can be an organization or position (e.g. data manager). To do this, enter the organization or position name under givenName and leave middleInitial and surName empty.
  -  Any other roles are acceptable and will be listed under associated party (e.g. Field Technician).
- **projectTitle** (optional) Project title the data package was created under. Only list project titles on lines where the personnel role is PI. If an ancillary project was involved, then add a new row below the primary project with the ancillary project title and associated PI. Repeat for additional ancillary projects.
- **fundingAgency** (optional) Agency the project was funded by. Only list on lines where the role is PI.
- **fundingNumber** (optional) Grant or award number funding the project. Only list on lines where the role is PI.

```{r personnelexample, echo=FALSE}

Table2<-read.delim(file="../dataPackages/dataPackageTemplate/metadata_templates/personnel.txt")

kable(Table2, 
      col.names=c("givenName","middleInitial","surName","organizationName","electronicMailAddress","userId","role","projectTitle","fundingAgency","fundingNumber"),
      caption="**Table 1.** Example Personnel Table.") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),full_width=F)

```

## intellectual_rights.txt 
The intellectual rights license describes how the data package may be used in the future. In most cases data should be released without restriction (CC0) and this file should *not* be modified.

> `r readLines("../dataPackages/dataPackageTemplate/metadata_templates/intellectual_rights.txt",encoding="UTF-8")`

## custom_units.txt
Typically not needed, but required if non-standard units are used in a data tables attribute.txt file. Custom unit definition and relation to SI units facilitates human and machine understanding.

**custom_units.txt** is a tab delimited table with columns:

- **id** Unit name (e.g. feetPerSecond)
- **unitType** Unit type (e.g. velocity)
- **parentSI** SI equivalent (e.g. metersPerSecond)
- **multiplierToSI** Multiplier to SI equivalent (e.g. 0.3048)
- **description** Abbreviation (e.g. ft/s) 

## Templates You Don't Need to Worry About 

1. **methods.txt** is automatically generated and directs the data user to the data release report.
2. **abstract.txt** is automatically generated from the abstract included in the data release report.

# Step 5. Create the Attributes Table
1. Run the script in Step 5 of the rmd file. This will inspect your dataset and create a text file in the `metadata_templates` folder.
2. Edit the `attributes_*.txt` file (required if data package contains data tables). Well documented data table attributes facilitate human and machine understanding.

**attributes.txt** is a tab delimited table with columns:

- **attributeName** Column name
- **attributeDefinition** Column definition
- **class** Column class. Valid options are:
  - **numeric** Numeric variable
  - **categorical** Categorical variable (i.e. nominal)
  - **character** Free text character variable (e.g. notes)
  - **Date** Date and time variable
- **unit** Column unit. Required for numeric classes. Select from the standard unit dictionary, accessible via the R console command view_unit_dictionary(). If not found, then define as a custom unit (see custom_units.txt).
- **dateTimeFormatString** Format string. Required for Date classes. Valid format string components are:
  - **Y** Year
  - **M** Month
  - **D** Day
  - **h** Hour
  - **m** Minute
  - **s** Second All separators of format string components (e.g. - /  :) are supported.
- **missingValueCode** Missing value code. Required for columns containing a missing value code).
- **missingValueCodeExplanation** Definition of missing value code.

```{r attributes, echo=FALSE}

Table3<-read.delim(file="./attributes_Example.txt")

kable(Table3, 
      col.names=c("attributeName","attributeDefinition","class","unit","dateTimeFormatString","missingValueCode","missingValueCodeExplanation"),
      caption="**Table 3.** Example Attributes Table.") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),full_width=F)

```

# Step 6. Create Category Variables Table
1. Run the script in Step 6 of the rmd file. This will inspect any fields you have identified as "categorical" in Step 5 and extract the categories into an editible text file.
2. Edit the `catvars_*.txt` file (required if an attributes table contains categorical class variables). Categorical variables require definitions to enable full understanding of data table contents.

**catvars.txt** is a tab delimited table with columns:

- **attributeName** The attribute to which the code or category applies
- **code** The code or category
- **definition** Column definition

```{r catvars, echo=FALSE}

Table4<-read.delim(file="./catvars_Example.txt")

kable(Table4, 
      col.names=c("attributeName","code","definition"),
      caption="**Table 4.** Example Categorical Variables Table.") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),full_width=F)

```

# Step 7. Set Geographic Coverage

- Option 1. Use the default in the template script, which is to just include a description of the area covered. If you do this, delete the **geographic_coverage.txt** file before creating the EML file.
- Option 2 (preferred when appropriate for the data). Edit the geographic_coverage.txt file. This will require you to query the dataset to identify locations. A function to do this is included in the EMLassemblyline package:

```{geocoveragecodesnippet}
# Template geographic coverage
template_geographic_coverage(
  path = './pkg_301/metadata_templates',
  data.path = './pkg_301/data_objects',
  data.table = 'nitrogen.csv',
  site.col = 'site_name',
  lat.col = 'site_lat',
  lon.col = 'site_lon'
)
```

**geographic_coverage.txt** is a tab delimited table with columns:

- **geographicDescription** Description of geographic point or area.
- **northBoundingCoordinate** North coordinate
- **southBoundingCoordinate** South coordinate
- **eastBoundingCoordinate** East coordinate
- **westBoundingCoordinate** West coordinate

Coordinates must be in decimal degrees and include a minus sign (-) for latitudes south of the equator and longitudes west of the prime meridian. For points, repeat latitude and longitude coordinates in respective north/south and east/west fields.

```{r geocov, echo=FALSE}

Table5<-read.delim(file="./geographic_coverage.txt")

kable(Table5, 
      col.names=c("geographicDescription","northBoundingCoordinate","southBoundingcoordinate","eastBoundingCoordinate","westBoundingCoordinate"),
      caption="**Table 5.** Example Geographic Coverage Table.") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),full_width=F)

```

# Step 8. Set Taxonomic Coverage
(Optional) Fully documented taxonomic ranks and authority IDs for each taxa enable data package discovery based on taxonomic search criteria.

**taxonomic_coverage.txt** is a tab delimited table with columns:

- **taxa_raw** Taxa name as it occurs in the data. Can be single word or species binomial.
- **name_type** (optional) Type of taxonomic name. Can be scientific or common.
- **name_resolved** (optional) Taxa’s name found in an authority system.
- **authority_system** (optional) Authority system in which the taxa’s scientific name was found (e.g. ITIS).
- **authority_id** (optional) Taxa’s identifier in the authority system (e.g. 168469).

name = taxa_raw, name_type = rep(‘scientific’, length(taxa_raw)), name_resolved = rep(NA_character_, length(taxa_raw)), authority_system = rep(NA_character_, length(taxa_raw)), authority_id = rep(NA_character_, length(taxa_raw)),

# Step 9. Set Temporal Coverage
This defaults to the date of the dataset creation. This should be edited to inspect the dataset for start dates and end dates or manually edited to reflect the temporal range of the dataset.

# Step 10. Create EML file
Run step 10. It will let you know if it finds any errors that need fixing. Ignore warnings about identifiers needed to post the dataset to EDI or other repositories. The EML file will be placed in the `eml` directory.

# Step 11. Create Manifest File and Package
Run the rest of the script. This will grab the csv file, eml file, and manifest file, zip them up, and then put them in the template's "output" folder.